# 한계
- 여전히 발생하는 AI가 자신의 몸으로 생성된 닫힌 방에 스스로를 가두는 상황
- 어쩔 수 없이 갇힌 방에 입장했을 때 생존할 수 있는 가능성이 있음에도 노련하게 대처할 줄 몰라 게임 오버를 자처하는 상황

---

# 해결 방안

## 예상 경로 시뮬레이션
- 현재 움직임이 장기적으로 어떤 영향을 끼칠지 예측하기 위해 다음 몇 턴 후의 예상 경로를 계산 및 남은 공간을 평가해서 이동함.

## `A* Algorithm` to 꼬리
- 갇힌 방에 들어가야 할 때 `A* Algorithm` 을 사용해 꼬리로 이동할 수 있는 경로가 존재하는 움직임이라면 출구로의 경로를 모색해서 이동함.

## 중후반에 방어적으로 움직이기
- 플레이어 몸이 맵을 대부분 차지하기 시작할 때, 방어적인 움직임을 취함으로써 차후 생길 위험성을 최소화 시키면서 이동함.

---

# 해결 방안 검토

## 예상 경로 시뮬레이션
- 먹이 개수가 여러 개가 될 경우 매 이동마다 타겟이 될 먹이가 달라지게 됨. 그러다보니 경로를 특정짓기 힘들 수 있음.
- 특정 메커니즘에 따라 타겟이 될 먹이 하나를 지정하게 되면 경로 또한 특정할 수 있다. 하지만 경로를 특정할 경우 전역적인 설정을 필요로함.
- 경로를 특정하는 과정에 있어 부하가 커질 가능성이 존재함.

## `A* Algorithm` to 꼬리
- 방법론적으론 매우 좋은 방법이나, 경로(path)를 기억하고 이동해야 하므로 전역적인 설정이 추가로 필요함. 게다가, `A* Algorithm`의 경우 탐욕적 탐색이 필요하기에 탐색 반경이 넓어질수록 부하가 크게 걸리며, 이 경우 게임 진행에 방해가 되지 않도록 비동기적으로 계산을 마치고 다시 경로로 돌아오도록 추가 설정이 필요함. 따라서, 구현하는 과정에서 많은 시간 소요가 발생할 것으로 예상됨.

## 중후반에 방어적으로 움직이기
- '방어적인 움직임'에 대한 정의가 필요함.
- **Rule-based** 방식과 결합될 가능성이 높음. 예를 들어, 맵을 한바퀴 두른 뒤 다음 먹이를 찾아 이동하고 다시 꼬리로 이동해 반복할 수 있다.
- 게임 진행이 속도면에서 늘어지게 될 가능성이 높음.
- 목적지 별로 현재의 이동 상태를 전역적으로 설정해야 함. 예를 들어, 꼬리로 이동하는 상태일 때는 꼬리로만 이동하도록 현재의 상태를 'to-tail'로 설정해야 함.

---

# 결론

중후반에 방어적으로 움직이는 방안을 택해 **Rule-based** 방법과 결합시켜 점수 상승을 노려볼 수 있음. 하지만, **RL(강화 학습)** 타이틀로 전환해 **Q-Learning**을 먼저 구현한 후 본격적인 비교를 할 때 다시 재개할 예정.